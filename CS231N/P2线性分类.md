![image-20230612162831820](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612162831820.png)

CV 核心问题：图像分类

这个问题很有挑战，当光照，类型，遮挡，明暗。。。。

### Nearest Neighbor

惰性算法，不用构建特征，不用训练，O(1); 而预测时O(N)

#### 图片数据集CIFAR10

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612164328595.png" alt="image-20230612164328595" style="zoom:67%;" /> 

32*32 RGB

图片相似度衡量：L1距离

选择L1距离最小的那个

边界是两点连线垂直平分线：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612165302926.png" alt="image-20230612165302926" style="zoom:67%;" />

#### 引出k-NN

L1距离对旋转的敏感的，L2距离不会。

CS231N小demo

#### 超参数

使用验证集（相当于模拟考试）

交叉验证

![image-20230612170058547](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612170058547.png)

遍历超参数，看准确率最高时是哪个

![image-20230612205334880](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612205334880.png)

L2是有缺陷的：没有区分度，复杂度太高。

K和距离度量指标是超参，可以用交叉验证选择。

优化：近的小伙伴权重高

### 线性分类

![image-20230612204753482](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612204753482.png)

代数表示、实例表示、几何表示 ↑

对应位置的像素乘对应位置的权重+偏置

### 损失函数

SVM常用的损失函数：铰链损失函数（合页损失函数）

s是预测结果，max(0, 线性预测最大值(正确值)-实际预测值+1)，可以想象，如果预测正确，损失函数会很小。还可以看出，损失函数会惩罚距离正确答案差距小于1的分类，比正确答案小更多的就不再惩罚了。

![image-20230612205933440](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612205933440.png)

初始化时，loss=类别个数-1

同一个损失可以对应多个权重 -- 》 正则化

正则化让权重更小，模型更简单，增加泛化能力。

L1， L2正则化，弹性网络： L1+L2正则化

#### softmax分类器

先指数运算，再归一化，得到概率

#### 交叉熵损失函数（最大似然估计）

![image-20230612213040497](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612213040497.png)

![image-20230612213515744](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230612213515744.png)

推导：概率相乘，但是为了防止小数太小，取对数，为了最小化而不是最大化，取负号。

### 梯度下降

 学习率，batch size

