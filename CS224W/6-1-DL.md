# 深度学习基础

> 同济子豪兄 2023-3-2
>

## 视频

中文精讲视频：https://www.bilibili.com/video/BV13g4y1n7b4

Youtube视频：https://www.youtube.com/watch?v=tutlI9YzJ2g&list=PLoROMvodv4rPLKxIpqhjhPgdQy7imNkDn&index=18

## 本讲介绍

斯坦福大学CS224W图机器学习公开课-同济子豪兄中文精讲

课程大纲、中文笔记课件、论文笔记、代码、思考题、扩展阅读、答疑群：

https://github.com/TommyZihao/zihao_course/tree/main/CS224W

本讲是深度学习基础课，介绍了深度学习的基本概念、应用场景、交叉熵等损失函数、反向传播和梯度下降优化过程，以及Mini-Batch优化、优化器、非线性激活函数等神经网络基本知识。

虽然当代的主流深度学习框架，都已经帮我们实现了自动求导、反向传播、优化更新，甚至调参优化，我们只需要做个“调参侠”、“炼丹侠”就行了。但洞悉深度学习黑箱子背后的数学原理仍然非常重要。

关键词：

Machine Learning, Deep Learning, Neural Network, Backpropagation, Cross Entropy, Stochastic Gradient Descent, Mini Batch, Non-Linearity

监督学习可以抽象为一个优化问题。

交叉熵损失函数：【-log(正确类别对应的概率)】再相加

有必要补一下：训练神经网络（权重初始化、激活函数、BN）：https://www.bilibili.com/video/BV1K7411W7So?p=7





## 扩展阅读

线性分类、损失函数、梯度下降：https://www.bilibili.com/video/BV1K7411W7So?p=3

神经网络、计算图、反向传播：https://www.bilibili.com/video/BV1K7411W7So?p=4

训练神经网络（权重初始化、激活函数、BN）：https://www.bilibili.com/video/BV1K7411W7So?p=7

训练神经网络（优化器、正则化、学习率策略）：https://www.bilibili.com/video/BV1K7411W7So?p=8

超有趣的神经网络可视化工具Tensorflow-Playground：https://www.bilibili.com/video/BV15J411u7Ly

卷积神经网络：公众号 人工智能小技巧 回复 卷积神经网络

循环神经网络：https://www.bilibili.com/video/BV1K7411W7So?p=17

生成对抗神经网络GAN：https://www.bilibili.com/video/BV1oi4y1m7np

## 思考题

什么是机器学习？什么是深度学习？什么是神经网络？它们之间是什么关系？

深度学习在语音、图像、文本领域，取得了哪些进展？

什么是“极大似然估计”？

推导多分类交叉熵损失函数

简述反向传播的基本原理

神经网络中的激活函数有什么用？如果没有，会怎么样？

SGD为什么是全局梯度的“无偏估计”？

Batch size的大小，会如何影响优化路径？

常用的梯度下降优化器都有哪些？各有什么特点？

## 特别感谢

赵冰辰（爱丁堡大学）

陈邵瀚（OpenMMLab）

